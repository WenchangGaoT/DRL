{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9n-gjTj1QTi"
      },
      "source": [
        "# Chapter 3: SARSA\n",
        "## Author: Wenchang Gao"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import gym\n",
        "\n",
        "import time\n",
        "import os"
      ],
      "metadata": {
        "id": "iqChZVLu1Sbd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Corridor and TD example"
      ],
      "metadata": {
        "id": "31Klz_td-_f_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Corridor:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.board = range(5)\n",
        "    self.state = 1\n",
        "    self.observation_space = 5\n",
        "    self.action_space = 2\n",
        "  \n",
        "  def step(self, action):\n",
        "    state_prime = self.state+1 if action == 0 else self.state-1\n",
        "    self.state = state_prime\n",
        "    done = (state_prime==0) or (state_prime==4)\n",
        "    reward = 1 if state_prime==4 else 0\n",
        "    return state_prime, reward, done\n",
        "  \n",
        "  def reset(self):\n",
        "    self.state = 1\n",
        "    return self.state\n",
        "  \n",
        "  def render(self):\n",
        "    for i in range(5):\n",
        "      print(i if self.state!=i else '*', end=' ')\n",
        "    print('')\n"
      ],
      "metadata": {
        "id": "xpxp-AS42hk7"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TabularSARSA:\n",
        "\n",
        "  def __init__(self, obs, act, gamma=0.99, epsilon=0.3):\n",
        "    self.q_table = np.zeros((obs, act), dtype=np.float32)\n",
        "    self.epsilon = epsilon\n",
        "    self.gamma = gamma\n",
        "  \n",
        "  def print_table(self):\n",
        "    for i in range(len(self.q_table)):\n",
        "      for j in range(len(self.q_table[i])):\n",
        "        print(self.q_table[i][j], end=' ')\n",
        "      print('')\n",
        "    print('')\n",
        "\n",
        "  def act(self, state):\n",
        "    prob = np.random.random()\n",
        "    # print(self.act)\n",
        "    action = np.random.choice(len(self.q_table[state])) \\\n",
        "            if prob<self.epsilon else np.argmax(self.q_table[state])\n",
        "    return action\n"
      ],
      "metadata": {
        "id": "8HZ2whBc_9gh"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the agent"
      ],
      "metadata": {
        "id": "qlTXozE-Cp65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainTD(agent=TabularSARSA(5, 2), env=Corridor(), episodes=100):\n",
        "  for epi in range(episodes):\n",
        "    display = epi%1000==0\n",
        "    if display:\n",
        "      print(f'Episode {epi}:')\n",
        "    state = env.reset()\n",
        "    if display:\n",
        "      env.render()\n",
        "    action = agent.act(state)\n",
        "    done = False\n",
        "    while not done:\n",
        "      state_prime, reward, done = env.step(action)\n",
        "      if display:\n",
        "        env.render()\n",
        "      action_prime = agent.act(state_prime)\n",
        "      agent.q_table[state, action] = reward+agent.gamma*agent.q_table[state_prime, action_prime]\n",
        "      state, action = state_prime, action_prime\n",
        "\n",
        "  agent.print_table()"
      ],
      "metadata": {
        "id": "oIZzakq-CnhQ"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainTD()"
      ],
      "metadata": {
        "id": "l4PycTP_MBEb",
        "outputId": "8672fded-879e-44ef-b279-4ee9947a44c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 0:\n",
            "0 * 2 3 4 \n",
            "0 1 * 3 4 \n",
            "0 1 2 * 4 \n",
            "0 1 * 3 4 \n",
            "0 * 2 3 4 \n",
            "0 1 * 3 4 \n",
            "0 1 2 * 4 \n",
            "0 1 * 3 4 \n",
            "0 1 2 * 4 \n",
            "0 1 2 3 * \n",
            "0.0 0.0 \n",
            "0.98010004 0.0 \n",
            "0.99 0.0 \n",
            "1.0 0.0 \n",
            "0.0 0.0 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HvJIPxsBMHhb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}